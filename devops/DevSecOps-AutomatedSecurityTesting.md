# Test


Welcome
- [James] Hi, I'm James Wickett and I'm the Head of Research at Signal Sciences. Are you in the field of IT security and feeling out of touch in the DevOps era? Or maybe you're a developer wanting to apply security testing in your software delivery pipeline. I help DevOps and cloud-first teams defend web applications, microservices, and APIs. In this course you will see how security and DevOps fit together as well as some guidance on how to get started with automated security testing. Next we'll move from guidance to practice. You will set up an attack lab to create your very own security automation test. When you complete the course you will have a reusable library of tests that can be put in place immediately in your organization.
Towards the end of the course we will cover how to do security testing in a continuous integration and continuous delivery pipeline. There are a few tricks to getting this right. Don't worry if you don't have a lot of experience with security tools or writing automated tests. In this course you will be up and running in no time.

What you should know
- [Instructor] This course walks you through building automated attacks that fit in a continuous delivery pipeline. In the course we use Docker, Git, and work a lot on the command line. You don't have to be a pro at this, however, some familiarity with these concepts will be helpful for you. Also, as you watch the course and you feel lost in continuous integration or continuous delivery concepts, I recommend checking out the DevOps foundation course in the library on that topic. Additionally, if you find the portions of the course covering web applications security vulnerabilities, too fast or may even not deep enough, I recommend checking out programming foundations web security, right here, available in the library.

1- Security Testing Basics

Security and DevOps history
- [Instructor] There is something we need to address before getting into into all the technical content. Security is an outsider in most organizations. Or, said another way, security is usually a silo much like operations was at the start of the DevOps movement. Now, you could pass over this statement and rush to implement solutions. However, that would be a mistake. Instead, let's take a brief moment and build some understanding that will help us do the security testing in the modern context of software development. One of the reasons security worked itself into being a silo is that it was born out of the waterfall methodology for software development.
The waterfall methodology envisions a project as a linear series of tasks, starting with project formation, then writing specifications, then doing development, then at the very end of a months-long, sometimes year-long process, testing occurs. Then security finally has a chance to review the project just before it goes to production. Now, as you have may experienced, this never works out exactly as planned. All too often, testing, not even to mention security testing, goes out the window in an effort to release on time. Security in this scenario will often be asked to do a review in a very condensed timeline.
And any problems they find often get ignored and just added to the next release. This not-so-virtuous cycle of ignoring security problems and then pushing them to later development cycles months or even years later causes an obvious tension. Security finds themselves in a situation where they have to block releases and argue to have bugs fixed. However, when you're a group trying to block releases, you're get labeled as the enemy. At one job I held, I was told by a developer that "Security is only happy when the system is powered off and unplugged." In other words, security in the minds of most people is just a blocker.
The flip side of this, I've often heard a lot of security people casually refer to developers as "those stupid developers." Now, I believed these views stem from organizational failures of waterfall. In the mind of a developer, security just tries to slow things down. In the mind of a security engineer, they see vulnerabilites being actively shipped out the door and no one willing to fix them. It is my belief that the many years we have spent doing security in a waterfall pattern has led to these misunderstandings and fostered and grew security into a silo.
Another important aspect to the current role of security is compliance. By compliance, I mean everything, from the credit card processing standard PCI to healthcare data with HIPAA, and more. The industry has been inundated with more and more compliance work. In many organizations, security engineers have been tasked with passing the compliance standard for the organization. While this is important work to pass audit, it often takes away from the day-to-day responsibilities of security engineering work.
Compliance standards are hundreds of pages long and full of legalese and take months to complete. This moves security away from providing actual security of the products and services the company provides, which is where the value is created. Instead, security moves precious resources into passing audit and becoming lawyers. Considering that most security teams are understaffed to begin with, this only makes the perception that security is a silo, that likes to slow things down, even worse, not better. The final wrinkle with information security discipline as a whole is this: risk management.
Much like compliance, risk management sneaks in a fallacy in our approach to security. I find this quote from Michal Zalewski in his book Tangled Web to be right on. He says, "Risk assessment introduces a dangerous fallacy: that structured inadequacy is almost as good as adequacy and that underfunded security efforts plus risk management are about as good as properly funded security work." Did you catch it? With compliance, we turn security engineers into an actuarial business.
Do you have a software vulnerability? No need to fix it, just buy an insurance policy for it and you're good. Needless to say, this doesn't actually make anything better. Please don't misconstrue that I'm suggesting waterfall, compliance, or risk management are inherently bad in and of themselves. However, I do believe that they've been applied to the industry over the years in ways that have led security away from solving the needs of the organization they are in. So, where does security go from here? One of the best things security can do is learn from the path of DevOps.
I mentioned earlier that I believe that security finds itself in a silo today much like operations was at the start of DevOps.

Security and DevOps for the first time
- [Instructor] Security and DevOps working together has a lot of names, DevSecOps, DevOpsSec, Rugged DevOps. The important part is not the name. Feel free to call it whatever you need in order to achieve the desired results, but the important part is adopting some new approaches to security. I recommend three main approaches to security in the area of DevOps. The first approach is to embrace the role of an enabler. In your mind, juxtapose this with security being a blocker. Instead of being the department or a team that blocks the release, be the department that helps everyone go faster and assert security quality at the same time.
In the end, the security team needs to understand this core principle. If you're a blocker, you'll be routed around. If you're an enabler then you add value. Now that sounds good on paper, but it isn't as easy in practice. One of the things I've seen work is to bring the security team together and ask, how can we help the overall software development pipeline go faster and be safer? Once you have a list, find the lowest hanging fruit and use small projects to test out your ideas. The next approach is to think about the software supply chain as a whole and look for places to add in security.
With the rise of a lot of the compliance frameworks, for many people security became more active. You add in a certain control because compliance says you have to. The new approach I'm recommending is to look from start to finish at your software supply chain and pinpoint areas where security can add value. Shannon Lietz who is a good friend coined the term DevSecOps. She has an excellent process for looking across your supply chain and asking questions to help identify areas to improve. I have a slightly modified approach and think of a software supply chain as these six areas.
First design, what do you intend your software to do? Can you make sensitive flows more secure? The next is inherit, what software have you inherited such as libraries and dependencies? What other layers of software are you inheriting from your OS or your service provider? Can you create a software a bill of materials so when a new vulnerability comes out for a certain library, can you know whether you have that or not? The next is develop, as you develop, are you writing tests for security? Ask if you're writing tests for auth for handling tokens and for the OAuth top 10.
Okay next is build, as you build your software, do you have security acceptance tests? For the deploy stage, what happens to get software into production? Are you securing config and secrets for the application and infrastructure? Lastly operate, are you under active attack at this very moment? Do you even know what is getting attacked? This course is going to hone in on some of the middle sections of the pipeline in order to add automation to do security testing in a devops context.
However, I want to stress that it is important to think from design to operation when evaluating the software supply chain. Okay, this leads us to our last approach. Create feedback loops to automate your security improvement. There are three main places I like to add feedback loops when getting started. First is the Continuous Integration or Continuous Delivery system, CI or CD. Sometimes it's referred to as the build system. Popular CICD systems include Jenkins or Bamboo or SAS tools like Travis or CircleCI.
If you're unfamiliar with these, there is a class I recorded with Ernest Mueller here in the library under the title DevOps Foundations: Continuous Delivery/Continuous Integration where we cover CICID in depth. Adding security testing to CI finds flaws in development and this is most often the best place to start with security automation. We will cover this in detail throughout the course and at the end of the course, we will put it all together with an example of adding security testing to a CI system. Next I look for where deployment happens. Generally there is a pre-prod or staging tier where changes get pushed before going to customers in a production capacity.
Sometimes deployment is handled by the CICD system itself, sometimes not. The goal is to test against something that looks and acts exactly like production does. This is a good place to run security attack tooling and anything that attempts to exercise several attack vectors in conjunction. I also like to put longer running attacks here so as to not slow down the build, but more on that in future videos. Lastly I look to production and try to monitor sensitive data flows against common attacks. Most of my experience is in running large-scale web apps, but the idea is the same no matter the system.
Look for areas to instrument that allows you to have feedback to answer, am I under attack right now? Using defensive tools like WAFTs or RASP for common web application security is a good start. Adding instrumentation around authentication events like password resets and failed logins gives insight into account takeover attempts. Really we can sum it up with our overall approach. Our whole approach here could be summarized as first change culture by adopting the identity of an enabler. Second, understand current state as you look across your software supply chain in order to remove blockers.
And lastly, create positive change through exposing feedback loops throughout your system.

Automated security testing basics
- [Narrator] There is a parallel between Operations at the rise of DevOps and Security where it is today. When DevOps when first was starting there was some thinking that operations was going to go away as a discipline as developers took all the responsibility away from the operations team. Infamously, it was coined as "NoOps". Now nothing could've been farther from the truth. Yes, the role of operations changed through DevOps and Ernest Mueller and I chronical this in our DevOps foundation course right here in the library. However, operations is now more important than ever.
Security finds itself very much at the same crossroads. When we automate security in the software delivery pipeline we are changing the role of what security has traditionally done in the past. We're not really eliminating it. Let's take a look at the role of the Penetration Tester. A good penetration tester follows the methodology that follows these four stages: reconnaissance, mapping, discovery and exploitation. In this class, we're going to take off the shelf attack tooling and instrument it into the development and build phases.
These tools cover a portion of Recon and Discovery however they're really just tools and only able to catch a piece of the overall vulnerabilities in an application. For example, they may catch a cross-eyed scripting flaw but they won't be able to explain how that attack can be used to put critical business assets at risk. By instrumenting your pipeline with attack tools you remove some of the low hanging fruit. Security's role now shifts to bring value by adding this automation and then adding their expertise on top of it.
So what are the types of tools we can automate? There are two main classes of tooling that we can automate: Dynamic and Static. In the industry there's a bunch of acronyms that describe tools like these; like SAST and DAST and IAST but for simplicity's sakes we're just going to think of them in these two broad buckets. Static testing or Static Code Analysis refers to running tools that attempt to find vulnerabilities within source code without actually executing the source code.
This can be accomplished simply through looking for band functions via Grep or using full-blown static code analysis tools like Open-Source Brakeman and FindBugs or commercial variants like VeraCode or Fortify. Ideally, these tools would run on every code command, however they can take a long time to run and require a bit of tuning to avoid all the false positives. In my experience these are not the best candidates to putting in the hands of developers without security working side-by-side on tuning as they're just too slow and full of false positives.
Another class of Static testing is Mapping and Inventory Assessment. These tools are excellent for development pipelines as they are fast and accurate. I really like using Retire dot js in any web project that I work on. It's simple to add and through my CI system it alerts me when I'm using a vulnerable version of JQuery or any other JavaScript library I might have bundled into my product. Now, there are several large commercial providers like: Sonatype, Black Duck, and Jfrog that plug in easily to source control and CI systems.
Okay, let's talk Dynamic. Dynamic tools actually interact with the running version of your application and attempt to find flaws and vulnerabilities at runtime. Unlike static testing, these have a lower false positive rate. However, they still aren't perfect. Dynamic tools are the same tools run by real attackers, attacking your application to find weaknesses. We can take these tools and harness them for our own testing. If the attackers are able to use them, well hey, why shouldn't we? Now there is a gotcha here, most of the dynamic tools can be slow and I mean painfully slow.
I've had many times where I turn one on come back hours later only to see there's 15 percent done. Other times they run so long they end up crashing my laptop. This is because most of them attempt to do all the phases of the penetration testing methodology. They do Recon, Mapping, Discovery and Exploitation. Dynamic tools can be run as a service through providers like Qualys or WhiteHat but I find them to be most useful when using open source attack tools and have them run on every code commit and every deploy. Some open source tools to consider in this base, Arachni, Nikto and ZAP.
We'll be using Arachni and others throughout this course. We will cover how to tune these tools so they can run fast and target specific areas of your application with the right types of attack payloads.

Tips for security automation for DevOps
- [Instructor] Before we start writing tests, I want to cover four guiding principles that can help avoid a lot of the problems that can occur when doing security in a DevOps or Agile context. Let's get to them. Up first, don't slow down the build. The build is the lifeblood of the development team. When it is slowed down or breaks, the team can't get work done or software released. One of your key tasks is to instrument security testing without adding too much time to the build. How much time is too much? Well, that depends on your shop, but I'm a believer in the Coffee Test.
If the build takes more time to run than it takes to go get a cup of coffee, then you have a problem. For that reason, I recommend keeping your overall build time, including all the security tests, to less than five minutes. If you find yourself in a situation where security testing is taking too long, then you might want to split tests into fast tests and slow tests. Keep the fast tests in the main build job, and move the slow tests to the side by having them run in a parallel build. Most build systems can handle this.
If you have really slow tests, you can run these on a nightly cadence, but use that as a last resort as you want to tie security testing to code commits as much as you possibly can. If you're having problem with build times, try to find developers or QA people in your organization that do stress testing and performance testing. They have the same sort of problems of long-running tests, and they can be a good source of ideas to overcome this in your organization. The next piece of advice is this. Don't block the build or the release.
Say your test identified a security vulnerability problem. Be careful not to outright block the build. This may seem antithetical to our purpose for the whole course, but security testing is tough to get right, and you need to be really sure it is a real vulnerability and not a false positive. Because of that, I recommend being transparent and giving feedback to the developers and security team when problems are found, but not breaking the build like a normal test failure would. Okay, so every rule is made to be broken.
There are some security tests you might want to block the build for, like credential exposure in the clear. This is where a culture of working together to decide what tests are the most critical and most worth blocking for. This brings up the next point. Expose as much security information as you can. The ChatOps movement brought operational information from monitoring systems all the way to developers, via chat interfaces and Slack and HipChat or IRC. Look for ways to expose discovered problems in your automated testing into the development communication platform of choice.
All the popular platforms have webhooks and integrations that are easy to report with. If you end up using a CI system with security testing, then most of the setup work will be pretty easy. Okay, on to the last word of advice. Have you ever had to fight with a library in Ruby? You know what I'm talking about you, Nokogiri. Well the next advice is born from lots of messing with dependencies and doing clean testing. The advice is to use containers for all attack automation and security testing. This eliminates problems from security tools requiring conflicting libraries themselves.
Also sometimes these tools save states from the run and commit a large result files and more problems. You're basically taking this off-the-shelf attack tooling and putting them inside of your testing environment. It only makes sense to block these off from the rest of the system. With these tips, you can avoid a good portion of the common pitfalls that come with doing automated security testing.

2- Security Automation: Getting Started

Setting up the demo environment
- [Narrator] Let's get our lab set up so we can start writing tests to be mean to our code. First you'll need to install docker. For the course I'm using a Mac with Docker Community Edition on it. Also called docker for Mac. If you have a Window's machine you can install Docker for Window's. If you're running Linux then the docker community edition is what you want. And just follow the instructions for your distro. Installation instructions and help are already available online at docker.com. This is a course on security testing and not on getting docker running. We will continue on assuming you have docker installed already.
The commands I run throughout this course in the terminal are using bash on a Mac. To work with Window's I recommend using the Window's 10 anniversary edition. You can install the Linux Bash shell. In this video, we're going to set up our vulnerable web application Gruyere. Gruyere is written in Python and is simple to get launched. In a browser I'm heading over to google-gruyere.appspot.com. One of the neat thing about gruyere is that you can run it for free online with no setup needed.
For our needs, we will be running it inside a docker container inside our system. However, it's good to know that this is available. Now let's click continue at the bottom of this page. And you'll notice that if you go to googe-gruyere.appspot.com/start you will get your own version of gruyere running in Google appenger. This starts a new instance with your own unique ID for you to discover application security vulernabilites inside of gruyere. Let's head over to the next page by clicking continue at the bottom of this one.
This takes us to part two, or our google-gruyere.appspot.com/part2. And you'll see that inside here are the labs for gruyere that give hints for what you can find inside the application along with exploitation code and advise for fixing them. In this class we won't be walking through this application but instead focus on creating automated security tests. Our course has a main repo and you can access a zipped up version of it in the exercise files, or you can pull directly from the public git hub repo.
You can see it at github.com/wicket/security-testing-class. I have git setup with by github keys and I'm switching to the terminal, and I'm just going to pull it down using git clone. I'm typing git clone git@github.com:wickett/security-testing-class. Once I move into that directory I can see all the files for the course. I'm typing cd ./security-testing-class.
Let's list them all out. I'm typing ls -la. Let's look at the Makefile. I'm typing cat Makefile. I pull this up because in this video we'll be using Make as it parses a Makefile for just a few helpers. To help make all the docker commands a little bit easier for us to remember. As I mention, we will be using gruyere but in a local container much like if we were developing a web application on our own. To do this we will pull a docker container from Karthequian, another instructor in the library.
It has gruyere already running in it. It is just docker pull user name and the docker that we're looking for. I've added a helper to our Makefile for this course and that'll help us get gruyere up and running. I'm typing make get-gruyere. This fetches the latest edition from docker hub and it makes available locally on our laptop. Alright good, we got it.
Now I've included two other helpers in our Makefile for working with gruyere. They are make gruyere start and make gruyere kill. Let's start it up. I'm typing make gruyere-start. Alright, it says that gruyere is ready to go on port 8008. In a web browser I can check that the application is running by visiting localhost:8008 in my browser. Let's do that now. Alright sure enough it's there. Now this site has lots of vulnerabilities built into it, and that makes it a great way to learn about different application security issues.
I can also head back to the command line and run docker ps. This shows me my container and what port it's listening on. As we go through the course you will start and stop gruyere. Let's go ahead and stop it. Now here we're using docker kill because every time we run it, we want it to be fresh. I'm typing make gruyere-kill. Once that finishes I can run another docker ps and sure enough it's gone. And this works just like we're hoping.
Alright now before we forget, let's go ahead and start it back up with a make gruyere start. Let me clear my screen here. With these few commands you should be able to work with the rest of the labs.

Web application security quick tour
- [Narrator] Make sure Gruyere is up and running by typing make Gruyere start. Now let's head over to localhost:8008 in a browser. When we are at the main page for Gruyere, the first thing I notice is that there is a user sign in and a sign up action. First thing we can do is go and head over and create an account. I'm clicking on sign up and using test for the user name and test for the password. Alright, my account's created. Now this gets me logged in. Now when I go back to the home I notice there's some new items in my menu.
There's My Snippets, New Snippets, Upload. Hmm, those all look very promising. I also see my username oddly reflected back to me in kind of a weird way. It might be worth looking into later. But uploading files kind of sounds like a good place for command execution or directory traversal. And that whole adding Snippets or New Snippets thing looks like a good place to take some user input. Maybe where data won't get validated. Well, why don't we just ahead and start there, we'll check that out. I'm clicking New Snippet. The site says it allows some HTML tags. Hmm, this kind of looks like a good place to inject something if these Snippets get reflected back to the user.
Maybe we can bypass the filtering they have and insert a little JavaScript to get cross-site scripting working. First, I'm just going to put in some plain HTML to see if that works. I'm typing the HTML bold tag and the word test and we're just going to close that out. And we're going to see if this Snippet gets uploaded. Okay, that worked and it did make it bold, so there is some HTML passing through. I wonder if we could do something like add a link. And now I'm going to try to do that. I'm opening up an HTML link. And we'll call this test two, and we'll close down our link here.
Let's see if that works. Alright, sure enough, the link gets made and it definitely looks like it's working. Well, that worked out well, so I might try just adding the HTML script tag, but that actually gets blocked. So I figured maybe we needed some way to let our script tag still get through. Since links work, maybe we could do a little something with that. In fact, as you interact with it, you might realize that some events like onmouseover are allowed. Let's add a third test here and see if we can get some cross-site scripting working.
So I've opened up a link tab. I'm added the onmouseover. I'm seeing if I can fire a JavaScript alert from here. We'll just call it alert one, and we'll just anchor it to itself, and we'll call this the ever-clever test three. Let me close out the HTML tag. Alright, now we have this, alert one. This is JavaScript, and so if this can get executed, then we have valid cross-site scripting.
Okay now, it looks like it added okay. When I mouse over that Snippet, my JavaScript alert gets triggered. Since other users in the system can see each other's Snippets, we now have a working example of a successfully stored cross-site scripting vulnerability. Now, if cross-site scripting is new to you, don't worry. Later in the course, we have several videos later explaining how cross-site scripting works and how to set up automated scanners to test for it. As you browse around the set, you see there is a Profile.
I'm clicking Profile in the menu. I'm sure this is another good place for us to look for more vulnerabilities. And you can have lots of fun with this. Our goal here was to look at Gruyere, and look at places where we could find vulnerabilities. In fact, here we only looked at one vector for cross-site scripting. There's several other areas on this site that have cross-site scripting. Inside Gruyere, there is also a command execution, information disclosure, privilege escalation, and much more. I recommend spending some time working through some of the Codelab on Gruyere over at google-gruyere.appspot.com.
There's a complete guide with hints and solutions for finding all the vulnerabilities in Gruyere. But now since our test site is up, let's go ahead and start looking some automated attack tools.

Application security attack tools
- [Instructor] Let's get hands on with the popular web application scanner Arachni. Scanners attempt to attack applications and find problems from cross-site scripting, or command execution, or other vulnerabilities. For our lab environment we're going to use a Docker container with the attack tools and Gauntlt already built into it. One of those tools is Arachni. In a browser I've headed over to www.arachni-scanner.com. Arachni is an open source web scanner with a command line and UI component. We will be working with the command line portion only throughout this course.
Out of the box Arachni is a first class web application scanner. It covers cross-site scripting, SQL injection, command execution, and more. Let's take a look at it on the command line but to do this we need to get our Docket container built and ready to use. Let's head over to github.com and look at the Gauntlt Docker repo. I'm typing github.com/gauntlt/gauntlt-docker into my browser. Now I'm selecting the Docker file inside the repo.
Let's look at this Docker file. Our Docker image uses Ubuntu. It installs Ruby, and a bunch of other OS packages. And then later you'll notice it installs Gauntlt and then other attack tools like Arachni. If we look at the way Arachni's installed you can see the source is downloaded and then is added to our operating system path inside of the container. Now if you need to add new or different attack tools this is where you would add them. Now let's go ahead and clone the Gauntlt Docker repo on our local machine.
I'm heading back to github.com/gauntlt/gauntlt-docker and selecting to clone the repo. I'll copy this statement here and head over to the command line. Okay I'm typing git clone and then I'm pasting the line that I just copied. Now that that's pulled down I'm ready to build my container. Let's change directories into gauntlt-docker and now I can build my container using our make file shortcut.
I'm typing make build. Now this step takes a bit so we're just going to speed it up here. Okay great. Once that's finished now I have a container ready to go. It has Gauntlt and a bunch of other attack tool built into it. I added a few helpers to the gauntlt-docker project to work with the container. Let's run make space help to see what our options are. One of our options is make interactive which gives us a shell inside the container we just built.
We will use this a few times throughout the course. Let's go ahead and run make interactive. I'm going to go ahead and clear my screen. This starts up our container and it gets me inside the container in an interactive shell. Now that I'm inside the container let's give running Arachni a try. Let's just run Arachni with the dash dash version flag. Alright everything looks good to go. This shows us we're running the latest version of Arachni. Now let's run a full scan using Arachni against our site gruyay.
I'm typing arachni and then http://docker.for.mac.localhost:8008. This scan executes all of Arachni's attacks or what Arachni refers to as checks. I'm targeting docker.for.mac.localhost because I'm inside the actual Docker container and Docker makes this handy little hostname available so that it can talk out to localhost. In fact I have another container gruyay running on 8008 also exported to localhost so they're able to talk across each other.
If you're using Windows there's a similar extension for Windows. It's docker.for.win.localhost. Scanners like Arachni have a built in spider that enumerates all the pages on a site. They build an index through crawling the site with all the links that it finds. The index also looks for fields and parameters on the pages to test. Some scanners will even try to predict unlinked pages for like slash admin and other pages and more. A scanner like Arachni has thousands of payloads it uses to test and it tests out each of these pages and fields.
As you can guess all this takes a lot of time and a lot of requests. So we're going to speed up this scan here with a little bit of movie magic. The scan took over six minutes and it found a bunch of problems in our sample application. Not all of these are actionable nor should you treat them the same. This is where the tester's experience and knowledge of the application really comes into play. For example you may just want to ignore the http only cookie whereas cross-site scripting vulnerabilities should be considered high priority.
In upcoming videos we will dissect this output further to make it a lot faster and a lot more actionable. Hopefully you see that for us to fulfill the goals we set out earlier of not slowing down the build and passing the coffee test we can't just set and forget these attack tools. There's a better way to run these tools in an automated testing fashion.

Security test automation with Gauntlt
- [Narrator] Let's take a look at a way to harness these attack tools we've been looking at. The tool we'll be using for this is Gauntlt. I'm a core developer behind Gauntlt and I'm really excited to introduce this project to you. Gauntlt is written in Ruby and runs using Cucumber, the very popular behavior driven development tool for Ruby. Now, don't worry. You don't have to know Ruby to use it. Gauntlt is open-source under the very flexible MIT license. Let's head over to the project's home over at Gauntlt.org. Gauntlt provides hooks to a variety of security tools and puts them within reach of security, development, and operations teams to collaborate to build rugged software.
Gauntlt works by wrapping attack tools and checking their output using plain text files that end in a .atk extension. To do this, Gauntlt uses Gherkin syntax which takes a plain English approach to testing. The key behind Gherkin are three words you, as an English speaker, already know how to use everyday. Those three words are: given, when, and then. These words function as the basis for Gherkin and also for Gauntlt. Let's break them down in turn.
First given. The given step should always encompass the assumptions you have about your test. Given I have this dependency installed. Given the test server is located at a certain address. Given the user name and password is. Basically all the stuff you expect to be true going into the test. Next, when. The when step could be summarized as the action step. When I perform an action. When I run this attack. When I try to access a file.
These are the actions that you're performing and this is generally the heart of the test. Next, then. Then steps take a look at the output from the when steps and asks does this meet all my expectations? Then the output should contain a certain value or then the output should not match. You can think of then steps as the result parsing steps. Now that's the basics of Gherkin and Gauntlt. Given, when, then. There are a few more other terms we'll discuss but this is the heart of it.
Those other terms are: Feature, background, and scenario. Each Gauntlt attack file has a core purpose. We call this the feature. I like to split up my attack files into logical groupings around the purpose of the application and the types of security testing being worked on. A good feature in an attack file might read something like this feature. Look for cross-site scripting, or XXS, using Arachni against a URL. This goes right at the top and it lets the reader know exactly what this attack is trying to do.
Next let's talk about scenarios. Each scenario runs independently of each other. You can share data across steps but not across scenarios. Since they are isolated, you can put multiple scenarios in an attack file under one feature. Now there may be some scenarios that have the same given steps. This is pretty common. In that case, we use background. Background stanzas as run before each scenario. Let's put this all together and look at a sample attack file. For this example, we're just going to read through this.
The feature says, this attack's purpose is to make sure the right ports are open on the server. Even though there is one scenario, there is a background stanza. This is good practice as it makes it easy to add new scenarios later. The stanza makes sure that the nmap is installed and it sets up a host variable. Next, the scenario runs and it has a descriptor. It says that it wants to find open ports. In this scenario there is a when and a then step. Notice how when is the execution and then is the output checking step.
This gets you started on how to write Gauntlt attack files and what they look like. Next let's write and run our own attack file from scratch.
Help/Feedback

Running your first automated attack
- [Narrator] Before we get to writing our attacks, we need to make it so that our development laptop can use Gauntlt. Since we have our nifty Gauntlt docker container, we can just call Gauntlt inside the container and pass our local attacks to it. You can also install Gauntlt as a Ruby gem if you want. But for this course we are just going to use the docker version. Throughout the rest of this course, you will see me call this as gauntlt-docker. And if you installed via Ruby gems, just use it as gauntlt instead. To get gauntlt-docker in your path, there's a helper in the bin directory in the gauntlt docker repo from the one that we cloned earlier.
Let's copy that into our path now. I'm typing cd to change directory into the gauntlt-docker repo. Now I'm typing cp, which is copy, bin/gauntlt-docker into user local bin. I can now run gauntlt-docker --help and it should just work. Alright, looks good. I'm going to clear my screen here. Let's write and run our first attack. The finished solution is in the exercise files under attacks/helloworld.
I'm moving into the course main repo with the change directory to security-testing-class. In my text editor vim, which is what I prefer to use you can use anything, I'm opening up hello-world.attack. Gauntlt looks exclusively for the .attack extension. The first thing I need to do is write what this attack is supposed to do. So here I'll type up the feature.
Hello world with gauntlt using the generic command line attack. Okay, well now the test has a purpose. Maybe not a very compelling one, but a purpose nonetheless. Now we need to add a scenario. I'm typing this scenario. Inside the gauntlt-docker container evaluate the user accounts. Okay so now we have a feature and a scenario.
Let's add our first step. In this example I'm going to skip the given step and just start with a when step. For other attacks we'll have given steps and background stanzas but for this one, since it's our first one, let's just get into it. Gauntlt has a generic command line adaptor and that's the one I'm going to use. I'm typing when I launch a generic attack with, and them I'm adding some triple quotes and saying cat etc password. The triple quotes here just create a string that gauntlt can then execute later. Now this is just looking at the etc password file inside the docker container.
Nothing too special here. But let's go ahead and save this and try to run it. I'm clearing my screen here. I'm typing gauntlt-docker and then attacks, hello_world, hello-word.attack. Now we can see we have one scenario with one step and it passed. It's sort of uneventful so let's make it a little more exciting. Let's add another step, but let's start with it failing first. I'm opening up our hello-world.attack using vim, my text editor.
I'm adding a new step to parse the output of the previous step. I'm typing then the output should contain, and I'm going to pass another string here. For our string, let's use the words Bill Gates. Of course there is Bill Gates here on the system. I'm wanting to actually invoke a failure here. Let's run it again. Let's save. I'm going to clear my screen and I'm going to run gauntlt-docker. And I'm going to pass in the pack to hello-world.attack.
Alright, it failed. There is no Bill Gates on the system. So notice here we had one scenario with two steps. One passed which was our cat etc password, the when step. And then the then step failed. If we want to get this to pass let's just check for a user we know should be on the system. Like the root user. I'm editing the last step and I'm changing it to then the output should contain root. Alright that looks good.
Now this should work. Once I save this and run gauntlt-docker again, it passes. Again I'm running gauntlt-docker and then passing in the hello-world.attack. Okay that's great. That's it four our first attack. These attack files are the way we run security tests and different attack tooling in development and throughout our entire software delivery pipeline. Gauntlt encapsulates the tool and provides a plain English way for users to interact with security.
Help/Feedback

3- Application Security Automation

Application security vector: XSS
- Cross-Site Scripting, shortened as XSS, is the perennial top vulnerability on the web-application security vulnerabilities list. Well, what is it? OWASP provides this definition: Cross-Site Scripting attacks are a type of injection, in which malicious scripts are injected into otherwise benign and trusted web sites. But what does that mean in practice? It means that since the browser executes JavaScript, the attacker is trying to get their own JavaScript to run with the execution of the rest of the page. The most simple XSS payloads is like this one here.
It opens inline script html tags, and fires an alert. When the attacker sees the alert return on their screen, they realize they have found a website that is vulnerable to Cross-Site Scripting. Cross-Site Scripting is a favorite of attackers because it is widespread and flexible. It works in all types of places where user input is accepted, and JavaScript is running. Which is basically every site on the internet. You can break up Cross-Site Scripting attacks into two classes: stored or reflected. For stored Cross-Site Scripting, you might be able to leave Cross-Site Scripting in comments or through changing your profile to contain the malicious script.
These get stored in the database and live on for other users to discover later. For reflected, they can be generated back to the user through search results or error messages. Attackers will use links that reflect the malicious script back to their target, and this is a common approach for phishing campaigns through email. But you may be thinking, "Isn't this just JavaScript, and not really that big of a deal?" Well think about all the things JavaScript has access to. The DOM, cookies, and a whole lot more.
Let's look at this example. If we can leave this as stored Cross-Site Scripting in say, a comment on a webpage, then we can get this code to run in other people's browsers. When they visit the page, then the current, valid cookie gets sent over to evilsite. Now the attacker has a valid user session that they can use. They don't even need a user name and password. Now there's a lot more you can do with Cross-Site Scripting. Enter BeEF. The BeEF project contains a JavaScript payload that turns browsers into command and control servers.
BeEF hooks one or more web browsers, and uses them as beachheads for launching directed command modules and further attacks against the system from within the browser context. I've used BeEF to hook browsers, and then do internal scans of intranets or pull down browser history from the hooked browsers. There's a lot you can do here. Since Cross-Site Scripting is so common, and can be very detrimental to our application's security, it is one of the best things to test for early in development. This is because even though it is widespread and a common target, it is pretty easy to fix through sanitizing user inputs and encoding any output from the application.
If you need resources for fixing Cross-Site Scripting, OWASP.org has plenty of resources. Okay let's get an attack tool like Arachni, and set it to test for Cross-Site Scripting using gauntlet.

XSS attack automation
- [Instructor] Security testing automation is a lot of fun, and now let's work with our first real automation test. Here we'll use one of our scanners to test for cross-site scripting on our test site, Gruyere. You want to make sure Gruyere is up and running. To do this, let's go to the main repository. I'm changing directories to security-testing-class. Now that I'm in here, I'm going to use make gruyere-start. Alright, this has Gruyere up and running on localhost port 8008. We can do a docker ps to check and make sure this looks good, and there it is.
Now, let's also open a browser and head to localhost:8008 to make sure everything is running. Alright, there it is, looks ready to test. Let's get to writing an attack. I'll clear my screen here and let's get started. I'm going to open up a new attack file, which I'll call xss.attack, and I'll put it into its own directory so we can logically group attacks together. The final version of this attack can be found in the exercise files. First thing, from the main security testing directory, I'm going to type mkdir and then ./attacks/xss.
Let's open up xss.attack inside there. I'm using vim, my IDE, for this. Now, I want to start with a feature and I'll type this one: Look for cross-site scripting using arachni against our site. Okay, that looks good, pretty simple. It tells us what we are testing and what tool we are using. Now features can have one or many scenarios.
So let's create a scenario right now. I'm typing do a quick check for cross-site scripting and verify no issues are found on the login page. Remember, the scenario needs to give the reader an idea for what is going on in the test. Try to use as plain English as you can. This scenario is clear on what we are testing for, what we expect to find, and where we are testing. Next, we need to get started running our tests.
Let's make sure the tool we want to use is installed. This best fits into a given step. Let's add our given step. I'm going to say given arachni is installed, simple enough. This is telling Gauntlet to look in the path for tools it needs to run. In this case, it checks the path for arachni. Since we are using Gauntlet docker, it has arachni already loaded in the path available inside the container. I really prefer this approach to put the Gauntlet and all the tools that I want to use all in one container.
This makes it easy for Gauntlet to access everything it needs and adds isolation of these attack tools to the rest of our development system. Okay, remember, the given step is all the assumptions for our test. Right now, our assumptions are incomplete since we have information about the attack tool arachni but nothing about the target, so let's add that. I'm typing and the following profile and giving a couple of values here. Gauntlet lets you add profiles with this simple statement to set up a name and a value, that makes a map here.
Here I'm adding a variable called url that I can later use in other steps in this scenario. You probably noticed I'm using a long host name here, docker.for.mac.localhost. This is a special helper that docker provides so that we can talk to the host machine. And in this case we are talking to another docker container that is running the Gruyere application on port 8008 exposed on that host machine. If you are using Windows, you would replace this with the host name docker.for.win.localhost.
You might have also noticed that I'm using some pipes here and I've got this table layout and I added some extra spacing and padding there. None of the spaces really matter, you could do that, I just did this for visualization. But the way it's laid out here with the name and value is important. So you always have to have the first row start out with name value and then you can put whatever values in below. Now our given step is all set up. Let's write our when step. I'm typing when I launch an arachni attach with and then I'm using some triple quotes here.
Gauntlet uses these triple quotes to separate out what commands it's going to run. Even though this is several lines long, it is all one step. Let's fill in between the triple quotes right now. For the actual arachni execution, I'm typing arachni and then I'm adding some flags here. I'm saying xss checks, scope page limit of one, and then I'm passing in url. This runs arachni and the basic xss check and it only tests one page. Notice we are using the less than and greater than brackets to reference our url variable, which we set in the profile.
Doing this is not required, but using this style helps you reuse these tests without hunting down hard-coded values. I could have easily just put in the value up above in the actual attack. Okay, this all looks good; the last thing we need to add is what we expect the result to be. For this, we will use a then step. I'm adding then the output should contain zero issues were detected. When arachni exits without any problem, it emits this message of zero issues were detected.
We're just telling Gauntlet to look for this. Okay, let's run it and see if it goes. I'm typing gauntlet-docker and then I'm passing in the xss attack. Oh no, this failed. Now, don't get too worried; I was actually expecting this. This error says that it timed out because it took longer than three seconds to run. Well, we can fix this by marking this test as a slow test. I'm typing the @ sign and slow at the very top of the attack and saving it.
By adding the slow tag to the top of the attack file, we're telling Gauntlet to let each scenario run for 30 seconds. Let's save it and run it again. Okay, now we see no errors and it runs okay. This got us running the xss payload in arachni and writing a check against the login page. We can extend this even further.
Help/Feedback

XSS attack automation refactoring
- [Instructor] Arachni ships with a lot of other checks. In our previous scenario, we were just using the basic cross side scripting check and only on our login page and it didn't find anything wrong with the site. However, as you know, GreeA is a vulnerable application and it does indeed have cross side scripting inside it. Let's set up a second scenario to do a more thorough job of testing the login page. We will still be using the same attack file. Let's reopen attacks slash XSS slash XSS dot attack. I'm opening opening up in vim my ID.
Now, I don't want to change our previous scenario. However, let's add a second scenario. I've just copied my original scenario and pasting it below. Since this is a new scenario, let's rename the scenario to this. Do a full XSS check and verify no issues are found against the login page. Okay, let's rename our scenario to this. Do a full check for cross side scripting and verify no issues are found in the login page. It's still mostly the same but here we're implying that we're doing a full or a broader scope of checks.
Notice how in each scenario I'm repeating my given margin. This might look a lot cleaner if we moved all these given steps to a background stanza since they're exactly the same. I'm going to just move these lines to the top of the file and let gauntlet know that these are background steps. The background executes before each scenario. Okay, this looks a lot cleaner now. Now, we still haven't changed our second scenario. In arachni, there are over 60 checks and attack payload groups. Out of these 60 plus checks, seven of them are cross side scripting related.
Previously we were just running the basic XSS check. Let's see what else is available to us. I'm going to my guantlet repo and typing make interactive to get a shell inside the gauntlet docker container. Let me clear my screen here. Okay, now I'm in the container. Now, let's see what arachni has available for other checks. I do this by typing arachni dash dash checks dash lists. Alright, that's quite a bit of text. As you can see, there's a lot of checks involved here.
Let's make this a bit more readable and do an alphabetic sort as well. Here, I'm grepping out the name of the checks and I'm sorting them. Okay, that's a little easier for us to look at. Notice, there are all these other cross side scripting checks. Arachni lets you execute multiple checks with a wild card operator. Before we adjust our gauntlet attack file, let's test out how arachni works.
Let's run arachni with all the cross side scripting checks against GreeA and we do this by typing arachni dash dash checks equals xss star. Again, I'll type it and then I'll resay it. Arachni checks... Alright, I'm typing arachni and then I'm passing in the checks. I'm using the wild card operator with XSS there. I'm still limited to just look at the login page with a page limit of one and I've given it specifically our docker for mac local host at 4008 at slash login.
Alright, let's run this. Now, arachni is showing that it found cross side scripting and it looks like it found it in the URL path. Notice that the output no longer says zero issues were detected and now says with issues, two. We can validate this in a web browser ourself. I'll open up a web browser heading over to localhost colon 8008 slash login. Now arachni says the problem is in the URL pack. Let's add a simple XSS attack to the URL.
I'm typing script alert one script and hitting enter. Okay, looks good. Alright, now I get a JavaScript alert message showing that yes, indeed we found cross side scripting. Now that we've used arachni and verified that it's a real cross side scripting problem, let's make sure to add this to our gauntlet attack. Let's exit out of the container. Let me clear my screen. And we'll go back to our security testing class repo. And I'm going to open up attacks, xss, xss.attack.
Now I'm just editing our statement for arachni to run all the cross side scripting payloads using the wild card operator after XSS. Alright, that'll get them all. Okay, this looks good. Let's go ahead and run it. This time, when we run gauntlet, we should see this error out as it will detect the cross side scripting problem. Let's test it out. I'm typing gauntlet dash docker and then I'm feeding in the attack file. Our first scenario still passes but yup.
Our second one fails. If we scroll up a bit, we see that we found the same errors we saw when we tested manually. This style of testing where we run the attack tools and then set them up in repeatable test. This is exactly the type of testing we want to accomplish. Now imagine handing this attack file off to a developer or other security engineer. This file can easily be extended to test other portions of the site or adjusted to completely different target. We have democratized security testing by putting plain English around these attack tools.

SQLi attack automation
- [Instructor] SQL injection, often abbreviated SQLi, and pronounced as SQLeye, is a common web application vulnerability, that is probably not unknown to you. It occurs when a user is able to add or inject their own SQL into the application. This means an attacker could read the database, or modify data in the database, or even use it to get access to the administration operations on the database. When you see news articles with thousands or millions of records being dumped, SQLi is probably the attack vector behind the scenes. OWASP.org has several examples, but this is probably the easiest to look at, to get an idea for SQL injection.
Here we're seeing select everything from the items table, with a specific owner and a certain item name, and it's taking fields in from a form. When all of the items get selected, instead of just the intended one, this is because the single quote closed out with the SQL, and the rest devaluates to a true statement. This could logically be represented as select everything from the items table. You can see where this is bad. Defensive measures for SQL injection can be accomplished through parameterized queries, using stored procedures, whitelisting, and managing database privileges, to name a few.
If you're looking for more info on how to defend against SQL injection, I suggest checking out OWASP's SQL injection prevention cheat sheet. There's a link to it in the course handout. This brings us to testing for SQL injection. There is a tool that is a favorite of security engineers, penetration testers and hackers alike, sqlmap. Sqlmap is an open source tool written in Python, that automates looking for SQL injection flaws and taking over of database servers. We can spend days talking about sqlmap with the number of options it has.
This is sort of a Swiss army knife of SQL injection. For our purposes, we're just going to narrow down the scope of the tool. Now, okay Gruyere does take user input, but it doesn't actually use SQL behind the scenes, so it's not actually vulnerable to SQL injection. But, we can still use Gruyere as a way to test for SQL injection. I will show you how to write an attack that tests our login page for SQL injection. This will give you a starting point for working with gauntlt and sqlmap in your own environment. For this, I'm going to our attacks directory, and looking for SQLi form.attack.
I've already started this attack file. You will notice that at the top, we've added a new tag of really slow. This lets gauntlt run for 10 minutes per scenario, whereas the slow tag only allows for 30 seconds. Like I said, sqlmap is pretty big. Next, you can see our feature. The feature says, run sqlmap against our target and test any web forms found on the page. And our scenario includes a given step, it says, given sqlmap is installed. For sqlmap, specifically it checks that Python is there, and that there is an environment variable of sqlmap_path.
That has to exist, and it automatically provides this as a lower-case variable to use in later steps. This is some behind the scenes magic that gauntlt is doing. You could make it a little more clear, by adding this as a variable under your target URL in the profile. Even though this happens automatically with gauntlt, and it isn't exactly clear when you're writing a test, if you were to run this step without all of gauntlt's expectations being met, it would provide some help text in the error message it returns to you. Alright so, let's add our when step, the actual execution of sqlmap.
I'm typing, when I launch a sqlmap attack with, and then I have my triple quotes, and now I'm going to add in my sqlmap statement. Here I'm calling sqlmap, using the sqlmap path variable, and giving it our target URL. Then I'm adding a verbosity of one, which is the default, then I'm telling it to run in batch mode, so it doesn't try to prompt for user input while it runs.
Next, you can see we're testing for a login form. I give it the --forms flag, to tell it to parse forms on the page. After that, you see the dbms SQLite here. Here I'm telling it to not waste any time trying to numerate or guess what the DB is. If I'm the developer, I already know what it is. Next, I give it the fields that I know that are on the form page that I want tested. Like I said, there can be a lot of options. Well let's go ahead and try to parse the output here.
Alright, let's add our then step. I'm typing, then the output should contain, I'm going to add my triple quotes again, and say, all tested parameters do not appear to be vulnerable. This is the message that shows up when sqlmap doesn't think that our form has SQL injection. Alright, let's save this and run it, and I'm feeding in the attack we just made into gauntlt docker.
Alright great, that passed. Now, it did take a while, it actually took 33 seconds. Now you might be asking, why are we tuning this attack so much? Well, we want it to be fast, because sqlmap is like ARACHNE. It will try to scan and enumerate everything. That can take a lot of time. As the developer, you already know where the forms on your side are. You already know what database you're using. You already know what form fields are being accepted.
You have the home field advantage here. So it's important to use that knowledge in advantage to tune these scanners to test faster, and more acutely, for your specific situation. Okay great, that finished. Everything looks good, and it did take over 30 seconds here, so that was really important we added the really slow tag to it. Running sqlmap like this, lets you put it inside of your delivery pipeline.

Automating a fuzzer
- [Instructor] One of the ways penetration testers and security engineers gain access to places they shouldn't be is just by guessing values for paths, or users, or whatever. This guessing is called fuzzing, and of course security testers don't generally do this manually, but instead they outsource this task to automated fuzzers. This can lead to all sorts of goodness, such as finding hidden admin pages, or finding temporary files with config information in them, sometimes it leads to finding test servers or test versions of the applications. In rare, but particularly damaging situations, entire backups of the database get discovered.
Fuzzers can also be used to attempt to overload the system by entering in a bunch of junk, or unexpected input, to crash the application. This can lead to error messages that disclose sensitive information or invoke a denial of service situation. These are just a few scenarios of how fuzzers are used. In this course, we are going to use the open source tool DIRB. DIRB is a fast, lightweight web fuzzer written in C. It uses dictionaries and lists to enumerate a web application's contents.
Now, unlike our other scanners, DIRB doesn't do anything with its findings, meaning, it doesn't attempt to exploit it, or exercise anything it finds, it just reports what it finds. This is perfect for putting in a gauntlt attack. Let's take a look at DIRB before we automate it. I'm heading over to the gauntlt docker repo we cloned. I'm typing in change directory, cd, to gauntlt docker. And now I'm using the make file to interactive access to the shell, so I'm going to type make interactive. Alright, I'm logged into my container, let me clear my screen.
Since DIRB is loaded in our path already, we can just run DIRB with no arguments. That will actually pull up the help menu for DIRB, so I'm just typing DIRB. There are several options for the tool that might be helpful for you. I find I use the -w flag when using it with gauntlt so it doesn't pause at warning messages. I also use the -f flag, which helps DIRB handle 404 pages a little more gracefully. The other two most common flags I use are the -capital x, to add an extension for the application I'm testing, for example like a php extension, and there's also a -n flag, which you can use to say ignore certain HTTP codes, like 301s, or 500s.
At the bottom of this help output, there are a few examples for your reference. DIRB works using a simple format of DIRB, then the URL to test, then the wordlist to use, and any options. In case you need more info on DIRB, in the course handout I've included a link to a short tutorial for using it. Let's move on, since fuzzing hinges on the payloads, let's do a quick list of what dictionary lists come with DIRB right out of the box. I'm moving into the wordlist directory, by typing cd ./dirb222/wordlists.
Let's look at the contents of this directory. I'm typing ls -la. There are several lists and files and dictionaries in here. Let's look at the common.txt. In common.txt, there's over 4500 entries. When I look at common.txt, I see all sorts of entries in the dictionary here. Being that it's over 4500 entries just in the small common.txt, this is fine if you're able to do this manually, and you want to do some further testing, but when automating with gauntlt, I prefer to use the smaller list for speed, and for tuning of our actual attack.
Now I'm typing ls -la ./vulns. Inside this wordlist directory here, there are lists that are tuned for app servers or languages. Do you have IIS? Or maybe you're using Apache or Tomcat. These are a must use, if you're using any of these servers, as they find example pages and configuration information that all too often gets exposed. One list I always like to use with gauntlt, especially in a CI/CD pipeline is test.txt. Let's take a look at it.
I'm typing cat and then ./vulns/test.txt. This is a very short list, with variations of the word test, testing, and demo in English as well as in Spanish. Now, I like this, because most organizations have a test portion of their application, or test data. These are generally meant to be used in a pre-production environment, but shouldn't be released in production. Let's add a gauntlt attack to check and make sure we don't accidentally expose anything like this on production. I've partially started an attack for this. You can find the completed version in our attacks folder under webfuzzer/dirb.attack.
Let's go ahead and open it. I'm clearing my screen here and logging out of the container, and I'm opening it up with my text editor, Vim. This should look pretty familiar to you by now. We are adding our slow tag to give us 30 seconds for each scenario. If you need more time, use the really slow tag. Our featuring scenario here tell us about the test, and next we see our profile. There are two variables we set.
DIRB_wordlist_path, and wordlist. Notice for DIRB_wordlist_path, we are listing it here, but letting the user know that it is actually being overwritten by the environment variable called DIRB_wordlist. This is good practice to be explicit, since gauntlt's use of environment variables isn't apparent to someone using it for the first time. Okay, now let's add our DIRB attack. I'm typing DIRB, and then I'm using the hostname variable, and then the DIRB wordlist path, and the wordlist I actually want to test.
The wordlist I'm using is vuln/text.txt. This uses all of our variables from the profile, and then we add the -w and -f flags. That helps us tune for error pages, and continue on past warnings, like we talked about earlier. Next, let's parse our output. I'm typing then the output should contain, and then saying found:0. Now this is the output that DIRB automatically puts out, and we're telling gauntlt that none of the words in the test.txt dictionary were able to be found in Gruyere.
Okay, let's save this and run it. Now, before you run this, make sure Gruyere is running. You can do that by typing make space Gruyere -start from the main security testing class repo. I already have it running for me, so let's just go ahead and run the attack. I'm typing gauntlt docker and then I'm feeding in the attack of DIRB.attack. Alright, my attack ran, and since it is running locally, it was pretty fast. This wraps up testing with with our web fuzzer DIRB, and hopefully gives you a taste of what you can do with it.

Network testing on the fly
- [Instructor] Ever leave the development or admin port open on production? Ever have admins or developers make changes to the network without approval? An easy way to make sure you don't have regressions or new ports being opened up is through network validation. Network validation is simple, and fun, with Nmap, an open source tool, which is short for Network mapper. Nmap is incredibly flexible, and able to do much more than check ports. It can also identify operating systems, and can fingerprint loads of things, from a MySQL database to a WordPress instance. It does this through the Nmap Scripting Engine, referred to as the NSE.
There are hundreds of NSE scripts available on nmap.org. Since Nmap is a much beloved tool of network engineers and security testers alike, let's get on with automating it. I'm opening attacks/network/port.attack in my text editor, Vim. By now, this is old hat for you. In this attack, we have our standard feature and scenario, and we make sure Nmap is installed. Additionally, we set up our profile. Okay, this attack is missing the when and then steps.
So let's start by writing our when step. I'm typing "When I launch an 'nmap' attack with:" And then saying nmap -F, which is the fast flag, and then giving the host variable from above. In this case, this is our docker.for.mac.localhost, which we've used several times throughout the course. Next, let's check our output. To do that, I'm typing "Then the output should match:" And then triple quotes. 8008/tcp open. This is Nmap's normal output.
Let's save it and run it. All right, great. This checks to make sure that the right port is open. And for us, this is port 8008. This match works under this scenario. However, sometimes Nmap has the output with extra spaces, and it can lead to failing tests, or flaky tests. Gauntlt needs to be smart enough to handle variations in output and still keep running. Until now, we've been happily looking at our output using one-to-one matches. But Gauntlt actually uses regex for any parsing step that has the word "match" in it.
Let's change our output to regex. I'm opening up the file again, and I'm changing our line to remove the space and add a \s+. The \s+ operator is a regular expression that will match one or more spaces between the word tcp and the word open. Let's make sure it still works, and lets run it again. Okay, we can see that regex worked. Now, knowing we have the power of regex, let's look at one more attack using Nmap.
This attack is already all done for us, and it's in the attack/network directory. I'm going to show it here using Cat. So I'm typing cat attacks/network/simple-regex.attack. In this file, we're verifying that the server is not available on standard web ports, which are the port 80 and port 443. To do this, we're telling Nmap to do a simple two port check.
Notice the output parsing in our then statement. We have two options here. One is an inline matcher that is delineated by using forward slashes. Now since Nmap has forward slashes in its output, we just swap the forward slash for the regex wild card, the dot operator. Also notice we're telling Gauntlt it should not be this output. For all of the output parsing we've done so far, we can do the negative match, as well, by specifying not.
Just like our next line. "And the output should not match:" And then we have port 443 here. The triple quotes here also let us do multi-line matches if we wanted or needed to. Because the triple quotes are the delineator here, we don't need to use the wild card dot operator from regex. We can just go back to using the forward slash. Okay, let's run this. But let me show you another little Gauntlt trick. I'm changing directories, and typing cd attacks/network. I'm going to clear my screen here.
When you run Gauntlt, it looks in any subdirectories and finds any files ending in .attack, and tries to run them. In here, we have our two attacks that we just looked at. Now I can run gauntlt-docker with no arguments, and it's going to find these files and execute them. So having no arguments, it runs both attack files that we just worked on, since they're in the same subdirectory where we ran Gauntlt from. So it looks like our network checks are working. And if you are looking for more network parsing, you might be interested in using Nmap's XML output format and Gauntlt's XML parser.
Check out the course handout for an example of working with the XML parsing. Of course there's a lot more to Nmap than just port checking. Also in the course handout, I've included a link to the freely available Nmap book, to give you some more ideas on how to use Nmap in your Gauntlt attacks.

"Be mean to your code" in practice
- [Instructor] So far, we've created automation to run attacks against our site. These attacks have been through the use of tools like the network tester Nmap, and the application vulnerability scanner, Arachni. We have automated a web fuzzer, and looked at several application vulnerability classes like cross edge scripting and SQL injection. Along with all this, we've used Gauntlt to wrap these testing tools so they fit better in a testing workflow. Gauntlt promotes the idea of "be mean to your code." This harnesses application attack tooling inside of the software development life cycle.
In the recently released book, Agile Application Security, there's a dedicated chapter on this topic, and they cover Gauntlt. Though not as in-depth as we've gotten here. In the book, the authors share my sentiment on how to do security testing. They write, "The goal should be to come up with "a set of automated tests that probe and check "security configurations and runtime system behavior "for security features that will execute "every time the system is built "and every time it is deployed." Okay, that's great.
But you might be wondering, where do I go from here? How do I take what I've learned here and put it in practice in my organization or my team? First let's take a look at how to extend Gauntlt's functionality for doing more testing. Let's start with Gauntlt syntax. Gauntlt uses Gherkin keywords. In the course handout, there is a Gauntlt cheat sheet. You will find these Gherkin keywords there for reference. These should look familiar, because all along, we've been happily working with Gauntlt, using given, when, then. Also, as we went, we discussed features, scenarios, and backgrounds.
These aren't completely new, but I'm putting them here so you have a reference. We also have been using the Gherkin operators. The triple quote to create a string, pipes for table declaration, and the @ sign for tags and # for comments. One note here on tags is that Gauntlt looks for specific tags of @slow and @reallyslow, which we've talked about. However, you can use whatever tags you want to create logical groupings of attacks. I often will tag attack files for classification using tags like @web or @network to group similar types of attacks.
Once tagged, you can run Gauntlt to execute only those tags by adding the -t flag, or you can also use --tags, and specify your desired tags, or tags you want run. Now, what about writing steps, or figuring out what other attack tools you can use? Let's move over to the command line, and type gauntlt-docker --help. The help menu shows you how to use Gauntlt, and since there aren't too many options here, let's go through a few of them. Let's start with the allsteps flag.
I'm typing gauntlt-docker --allsteps. This shows all the steps that are available for us to use in any Gauntlt attack file. There are two portions. At the top of this output, there are all the steps that Gauntlt uses for file and output parsing. Gauntlt loads these from the Aruba library, which is part of Cucumber. They are under the heading "File and output parsing steps." These are worth reading through to be familiar with. Below that section, there's the heading "Gauntlt attack steps." These are all the attack steps we've been working with.
You probably notice the Gherkin keywords of given, when, and then aren't here. That's because these words are English words that are helpful for us, but Gherkin treats them functionally equal. You can use given, or when, or then, with any of these steps. I've taken some of the most common steps here and put them in the Gauntlt cheat sheet with the course handout. Another option to look at is the --format option. You can use this to emit formatted output. Let's try it out and generate some HTML output.
I'm going to call my hello_world attack here. And I'm going to add the --format. We're going to set it to HTML. I'm going to save it out to out.html. Now I have the output from the run on disk in the out.html file. I am now opening that up in a browser, and we can now see our output. If any of the steps had failed, it would've been colored red.
This is really useful for reporting. This should get you ready to write more Gauntlt attacks. However, you may be wondering what security tests you should look to next. I recommend going back to some of the tools we've already looked at, like Arachni, and looking at all the other checks we didn't use. Another good way to get ideas for tools to use is to ask Gauntlt what attack adapters it provides. To do this, let's look at --list. This shows all the attack adapters that are available. Don't misconstrue that Gauntlt somehow installs these.
Instead, it has helpers built in to handle them. However, in our Gauntlt docker image that we've been using, we've installed a few of these tools already. Notice here that there's a generic attack adapter. This adapter allows you to execute anything you can run on the command line. If Gauntlt doesn't already provide an attack adapter for your tool, just use the generic attack adapter. The exercise files included with this course are one way to get started. However, you can find more examples of attack files on github in two places.


4- Security Testing in Software Delivery Pipelines

Shift left and the DevOps way
- [Instructor] Continuous delivery has made a huge impact on business today. It seems everyone is working on delivering software faster. Even though continuous delivery hit the scene after DevOps, it soon came to be one of the hallmarks of doing DevOps. At Signal Sciences, where I work, we deploy 10 to 15 times per day. We like to measure deploys and total cycle time. That is the time from code commit, to running and production. Generally our total cycle time is around five minutes, with three or so minutes going to the build, one minute or so for testing, and 45 seconds to a minute for deploys.
Signal Sciences is a SAS based security company that defends web applications, micro services, and APIs in real time for some of the largest web scale companies. Our ability to deploy changes rapidly means we can get new features out to our customers as soon as our team has them ready. But since we're a security company, how embarrassing would it be if we shipped something like cross site scripting out the door? Security testing on every code commit and deploy is critical for us. I helped build the deployment pipeline at Signal Sciences, and in it we have Gauntlt in a Docker container to run test just like the ones we've build in this course.
This is shifting left. In a waterfall software development life cycle, all the testing gets done at the far right. Moving tests closer to when the code is being written is the shift left. Now, the test we've been writing throughout this class can all be applied to a CICD pipeline. There is one issue here. You might have noticed in each test we set up a profile and then added our special host name available from Docker, that's the Docker.for.mac.localhost, or if you're Windows it would be .win in there.
That's fine for local development and testing, and working on my host machine. However, your CICD system is probably a Linux system, so what do you do? Gauntlt has environment variables that you can set in the config. They work like environment variables in Cucumber, if you're familiar with those. You drop them into a config directory in a file called cucumber.yml. The contents of cucumber.yml look something like this. Here, TARGET_HOST would be usable as a variable inside your Gauntlt attacks.
Consider this background stanza. It uses an approach similar to regular profiles, but instead of the name value row at the top, it is changed to name, and environment variable name. This loads cucumber.yml and looks for the environment variables there. It is important that you have the config directory where the cucumber.yml is stored is the same location as where you're invoking Gauntlt. If you need more help with this, there's an entry in the Gauntlt wiki on this topic, and the link is in the course handout.
With this in mind, let's set up a CI system.

Security testing in CI/CD
- [Instructor] For continuous integration for the course, I decided to go with Travis CI. Travis CI was the first to turn continuous integration into a software as a service offering, and I've used it for many years. I really like Travis CI as they're a software as a service offering, but they're free for open-source projects to use. At Signal Sciences, we use a similar setup that I'm going to show here, but we do it all in Jenkins. The actual CI system is not that important as long as it supports using Docker containers. I am opening my browser to travis-ci.org/wickett/security-testing-class.
I can see the latest build and the results. Travis shows me red or green, whether I passed or failed, and how long the whole thing took. There is a badge that you can insert into a webpage that shows your current status. Now we'll click Build History, and I can see the status of all the past jobs that I've run. This all looks great, but how is it all set up? Let's head over to our security testing class repo in GitHub.
This is at github.com/wickett/securitytestingclass. In here is a file called travis.yml. This is the config that Travis uses as instructions for the build. Let's check it out. The first few lines are letting Travis CI know what kind of instance to put on the job and tell Travis CI to use Docker. Next, we have a stanza of before_install. In here, we have taken some of the shortcuts from our make file and added them here.
Since our demo uses two Docker containers, I've made sure to pull both of them here. Travis CI works just like our development environment. It will run gruyere as a daemon on port 8008, and then we'll use our second container, gauntlt-docker, to execute attack files. This is just like what we've been doing, only now it is our CI system that is doing the heavy lifting. There's a line in here that says ./scripts/travis-config.sh. Let's take a look at this.
I'm moving up a level, and then opening the scripts directory and clicking on travis-config.sh. This script finds the IP address of the host, and then sets the environment variable in the config/cucumber.yml. It sets this up as a TARGET_HOSTNAME environment variable. This isn't a permanent change. It's just for the build. Let's go back to our main config over at the root of the project in .travis.yml. In this script portion, the long statement here is just telling Travis to use gauntlt in a Docker container, much like we've been doing throughout the course in our helper script gauntlt Docker that we put in our path at the start of the course.
Notice what attacks we're running here, hello-world and our environment variables attack. I also took the cross-site scripting attack and made some changes. Let's open up attacks/ci/xss.attack. This is in the exercise files of course, but let's just view it in GitHub. Notice how it is using our environment variable approach. Also, at the bottom, I've changed it so that even though it detects two cross-site scripting issues, it will still pass.
You obviously don't want to do this in real life, but this is just for the demo. Now that we've worked our way through the configuration of Travis, let's fire a build and check the results. Any change, no matter how small, will invoke the build to run. So instead of heading back to the command line, let's just stay in the browser, and let's do all of our edits from here. I'm opening up the readme and making a small change to the readme, which will kick off a build. Add a little message in here. It says, "Thanks for watching, and be sure to star this repo if you like the course." Now I've committed this change, and this launches a Travis CI run.
Let's head back over to Travis CI and watch the build run. Since this takes a little time, we will speed it up. The build looks good. We can see that our Docker containers got downloaded and then our attacks got run. This puts security testing alongside other tests, and this approach can work for almost any CI system you're working with.
Like I said, even though we did this in Travis, at work, we use Jenkins in the same fashion. We've run over 10,000 deploys through it in the last two years. Security has to be part of delivering value, and we move security tests to where the code is being written as much as we can.

Conclusion
Start automating security testing
- Now you have the basics down, where do you go from here? If security testing and automation was just about using a new fangled tool, then this would be easy. However, this effort is a cultural shift, and requires engaging the teams responsible for building, and delivering your application. When starting out automating security testing, I recommend that people start slow, it's important to realize that security testing is a process. Like any cultural change, there needs to be an environment of shared understanding, created between those involved. Knowing that security is not trying to be a blocker, but is instead trying to be an enabler, goes towards that goal.
This builds up a mutual respect between the groups, where there is traditionally been finger pointing, and blame between development and security groups. This all comes together with focusing on collaboration. Development, security and operations collaborate together on adding security to the software development life cycle, and delivery pipeline. I find that most people doing the form of testing that I've recommended in this course, end up building a suite of tests inside their organization. These tests are often reusable between teams because the projects share development languages, data back-ins, and are deployed on the same cloud infrastructure.
Often, these are even being employed by the same people as agile and dev-ops principles move developers to the work. All of this lends itself favorably to a reusable suite of security tests. When making these tests, you may feel that you want a 100% coverage of an application. However, I recommend starting small, and be willing to start with even 20% coverage. Automated security testing has moved earlier in the life-cycle, and is trying to find even the low-hanging fruit. So even 20% now is better than leaving it all to the end of the project.
Lastly, we've talked about this many times throughout the course, but make sure security testing is fast, and not on blocking. Otherwise, it won't be adopted. But what about the people making security testing a reality in your organization? The first step is to involve security engineers. I find it useful to ask, "What manual security testing "tools do you use most frequently?" I also like to ask, "What are the most common "security problems you find in this organization or team?" Once you find out their normal tooling and their biggest concerns, you have common ground to start working together to create automation around that.
Next, make sure you involve operations. I love to ask operations teams, "What security "issues are you most worried about?" I also ask, "What is getting most attacked right now?" And, "What kind of attacks are they?" I generally find operations teams are worried about SSL or server security issues, you know in light of heart bleed and shell shock, and the struts two vulnerabilities of recent years, I mean, who can blame them. However, I don't often get a great answer to what types of attacks are we getting right now.
As this generally takes additional operational instrumentation, that most places really just don't have. But if you do get an answer, then you easily have a priority for automation, but if not, that's okay, just punching down the o-wasp top 10, that's probably a really good place to start. Lastly, I like to ask developers, "What parts "of the application "are you most worried about getting attacked?" I get the best answers from developers, usually revolving around authentication or sessions. These are excellent places to collaborate on. Developers are really familiar with the concept of regressions like past software bugs occurring again, because of this asking, "Have we had "security problems in the past with this application?" That's another great place to start.
I mean, why not write up a script to attempt to invoke an old problem, to assure that it won't come back and get us in the future. That's an excellent place to start with developers. Okay, I'll close out with this on how you work with third-party security consultants. Now, don't worry, the company I work for, Signal Sciences, we provide a security defense product, but not consulting. So I'm not going to give you a pitch or anything here. What I am going to recommend is when you work with auditors, penetration testers, and other security consultants, ask them to deliver a test that you can put in to your automation suite.
I call this my policy of deliver tests, not PDF's. If they refuse, then hey, you know it's time to find a new consultant. No matter where you find yourself, whether as a security professional, or a developer, or an operations engineer, the best time to start is today.

Next steps
- [Instructor] As we wrap up the course I want to leave you with some next steps. I'm reminded of Steven Bellovin's comment in the opening of his recent book, Thinking Security. Companies are spending a great deal on security, but we read of massive computer-related attacks. Clearly something is wrong. The root of the problem is twofold. We're protecting the wrong things, and we're hurting productivity in the process. Through this course I hope you're able to turn this trend around inside your team or organization.
You're now armed with the tools and practices that will get you protecting the right things and increasing overall productivity. My friend Shannon Lietz is fond of saying, safer software sooner. Throughout the course, we have built up some automated security testing, and through the exercise files and the course handout you have resources available to dig deeper into many of the topics we've covered here. One of the best ways to get automating is to spend time using the tools we worked with in the course but in new ways.
Using more of their features or scoping them to pinpoint issues that are relevant to your technology stack. If you're new to DevOps I encourage you to look here in the library for some other resources. Ernest Mueller and I have recorded several other courses on the subject of DevOps. If you find yourself needing more help with CI/CD efforts, I encourage you to look at the course DevOps Foundations Continuous Delivery and Continuous Integration. If you need more of a primer on DevOps then be sure to check out DevOps Foundations. Since Ernest and I both have a background in security, and we believe in joining the security tribe to the DevOps tribe, each of these courses has a section dedicated to security.
Thanks for joining me on this journey together, and I hope you enjoyed the course. Good luck, and I hope you have fun as you get started with security testing.



